{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "784ee97e-e4bd-4e22-86c6-5fa8ecb45560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e66f298d-cfff-45e2-abfe-a4d397bec41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movement_path = './pads-project-main/data/movement/'\n",
    "tabular_path = './pads-project-main/data/ptables/'\n",
    "\n",
    "X_movement, X_tabular, Y = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2630e28-34d1-448c-93bf-5d3cabc67ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Sample movement files:\n",
      "['001_ml.bin', '002_ml.bin', '003_ml.bin', '004_ml.bin', '005_ml.bin']\n",
      "\n",
      "ðŸ“‚ Sample tabular files:\n",
      "['001_tbl_ml.bin', '002_tbl_ml.bin', '003_tbl_ml.bin', '004_tbl_ml.bin', '005_tbl_ml.bin']\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset pathes\n",
    "print(\"ðŸ“‚ Sample movement files:\")\n",
    "print(sorted(os.listdir(movement_path))[:5])\n",
    "\n",
    "print(\"\\nðŸ“‚ Sample tabular files:\")\n",
    "print(sorted(os.listdir(tabular_path))[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7834f87-b4e6-46f9-bc4f-ad5974eceff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for bin_file in glob.glob(f\"{movement_path}/*_ml.bin\"):\n",
    "    if \"_tbl_\" in bin_file:\n",
    "        continue  # skip tabular files\n",
    "    p_id = os.path.basename(bin_file).split('_')[0]\n",
    "    tab_file = f\"{tabular_path}/{p_id}_tbl_ml.bin\"\n",
    "\n",
    "    if not os.path.exists(tab_file):\n",
    "        continue\n",
    "\n",
    "    # Load movement (sensor) and tabular data\n",
    "    sensor = np.fromfile(bin_file).reshape(-1, 1)  # reshape if needed\n",
    "    tabular_df = pd.read_pickle(tab_file)\n",
    "\n",
    "    label = int(tabular_df[\"con_lbl\"].values[0])  # assuming \"condition\" is encoded as int at position 2\n",
    "    \n",
    "    # Drop non-numeric columns before saving tabular features\n",
    "    non_numeric = [\"p_id\", \"s_id\", \"con\"]  # keep 'con_lbl' for label\n",
    "    tabular_numeric = tabular_df.drop(columns=non_numeric).astype('float32').to_numpy().squeeze()\n",
    "\n",
    "    X_movement.append(sensor.astype('float32'))\n",
    "    X_tabular.append(tabular_numeric)\n",
    "    Y.append(label)\n",
    "\n",
    "    # X_movement.append(sensor)\n",
    "    # X_tabular.append(tabular_df.to_numpy().squeeze())\n",
    "    # Y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a0ccfee-01c5-4903-ac82-aa553fa9f7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Movement samples: 469\n",
      "# Tabular samples: 469\n",
      "# Labels: 469\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Movement samples: {len(X_movement)}\")\n",
    "print(f\"# Tabular samples: {len(X_tabular)}\")\n",
    "print(f\"# Labels: {len(Y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4995868e-02c1-46e1-8520-bb75fb301b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[  1.  54.  44. 165.  67.   1.   0.   0.  -1.  -1.   0.   1.   0.   0.\n",
      "   1.   0.   0.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tabular[468]))\n",
    "print(X_tabular[468])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8426b9c0-47e0-4945-940a-f84b171cf926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36bf84fe-c08f-4060-ad23-4adf84bb9631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, X_movement, X_tabular, Y):\n",
    "        self.X_movement = [torch.tensor(x, dtype=torch.float32) for x in X_movement]\n",
    "        self.X_tabular = [torch.tensor(x, dtype=torch.float32) for x in X_tabular]\n",
    "        self.Y = [torch.tensor(y, dtype=torch.long) for y in Y]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_movement[idx], self.X_tabular[idx], self.Y[idx]\n",
    "\n",
    "# Example usage:\n",
    "dataset = MultimodalDataset(X_movement, X_tabular, Y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "807b3de4-6085-49d0-b096-65b4814f8b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=4, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        return self.norm(x + attn_out)\n",
    "\n",
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, input_dim_tabular, seq_len, input_dim_movement):\n",
    "        super().__init__()\n",
    "        self.movement_encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_dim_movement, 32, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(32),\n",
    "        )\n",
    "        self.tabular_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim_tabular, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.attn_movement = AttentionBlock(32)\n",
    "        self.attn_tabular = AttentionBlock(64)\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(32 + 64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)  # 3 classes: Healthy, Parkinson's, Other\n",
    "        )\n",
    "\n",
    "    def forward(self, movement, tabular):\n",
    "        # movement: [B, T, 1] â†’ [B, 1, T]\n",
    "        movement = movement.permute(0, 2, 1)\n",
    "        move_feat = self.movement_encoder(movement)  # [B, 32, 32]\n",
    "\n",
    "        # attention expects [B, Seq, F] â†’ transpose from [B, 32, 32] to [B, 32, 32]\n",
    "        move_feat = self.attn_movement(move_feat.transpose(1, 2)).mean(dim=1)  # [B, 32]\n",
    "\n",
    "        tab_feat = self.tabular_encoder(tabular).unsqueeze(1)  # [B, 1, 64]\n",
    "        tab_feat = self.attn_tabular(tab_feat).squeeze(1)      # [B, 64]\n",
    "\n",
    "        fused = torch.cat([move_feat, tab_feat], dim=1)        # [B, 96]\n",
    "        return self.fusion(fused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021d3afd-a5a8-428b-9b7c-57f39152cbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim_tabular = X_tabular[0].shape[0]  # Or check dynamically via code\n",
    "model = MultimodalModel(\n",
    "    input_dim_tabular=input_dim_tabular,  # example\n",
    "    seq_len=64416,\n",
    "    input_dim_movement=1   # âœ… Make sure this is 1!\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc01f5f6-72b4-4109-acf9-af97b4db0655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movement' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput to Conv1d:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmovement\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movement' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Input to Conv1d:\", movement.permute(0, 2, 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ba0143a1-4682-4202-9f00-67b4a45be3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b239c1d0-50c2-4cca-859e-2a4027f36b66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 1.0187 | Accuracy: 57.57%\n",
      "Epoch 2 - Loss: 0.9723 | Accuracy: 58.85%\n",
      "Epoch 3 - Loss: 0.9553 | Accuracy: 58.85%\n",
      "Epoch 4 - Loss: 0.9481 | Accuracy: 58.85%\n",
      "Epoch 5 - Loss: 0.9536 | Accuracy: 58.85%\n",
      "Epoch 6 - Loss: 0.9455 | Accuracy: 58.85%\n",
      "Epoch 7 - Loss: 0.9466 | Accuracy: 58.85%\n",
      "Epoch 8 - Loss: 0.9419 | Accuracy: 58.85%\n",
      "Epoch 9 - Loss: 0.9383 | Accuracy: 58.85%\n",
      "Epoch 10 - Loss: 0.9458 | Accuracy: 58.85%\n",
      "Epoch 11 - Loss: 0.9407 | Accuracy: 58.85%\n",
      "Epoch 12 - Loss: 0.9339 | Accuracy: 58.85%\n",
      "Epoch 13 - Loss: 0.9320 | Accuracy: 58.85%\n",
      "Epoch 14 - Loss: 0.9307 | Accuracy: 58.85%\n",
      "Epoch 15 - Loss: 0.9319 | Accuracy: 58.85%\n",
      "Epoch 16 - Loss: 0.9304 | Accuracy: 58.85%\n",
      "Epoch 17 - Loss: 0.9251 | Accuracy: 58.85%\n",
      "Epoch 18 - Loss: 0.9222 | Accuracy: 58.85%\n",
      "Epoch 19 - Loss: 0.9140 | Accuracy: 58.85%\n",
      "Epoch 20 - Loss: 0.9174 | Accuracy: 58.85%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        movement, tabular, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(movement, tabular)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4601843-1b75-45c2-ae05-e892b6654174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TS_BERT(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=4)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, input_dim)\n",
    "        x = self.embedding(x)  # (B, T, hidden_dim)\n",
    "        x = self.encoder(x)    # (B, T, hidden_dim)\n",
    "        x = x.transpose(1, 2)  # (B, hidden_dim, T)\n",
    "        x = self.pool(x).squeeze(-1)  # (B, hidden_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "88d3af00-6bde-468b-9b54-ff3a60c0c707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, input_dim)\n",
    "        out, _ = self.lstm(x)\n",
    "        return out[:, -1, :]  # or use mean pooling: out.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "078153f3-30d1-4a3f-adf5-490790e15d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/env_dl/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "movement_encoder = TS_BERT(input_dim=1, hidden_dim=64, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6b4461b4-c919-4a5d-a1c0-9df846145f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular_encoder = nn.Sequential(\n",
    "    nn.Linear(input_dim_tabular, 64),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(64 + 64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 3)  # 3 classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7822e-71c3-4714-b901-f30aabe5926b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 14.8345, Accuracy: 56.72%\n"
     ]
    }
   ],
   "source": [
    "movement_encoder = TS_BERT(input_dim=1, hidden_dim=64, num_layers=2)\n",
    "tabular_encoder = nn.Sequential(nn.Linear(input_dim_tabular, 64), nn.ReLU())\n",
    "classifier = nn.Sequential(nn.Linear(64 + 64, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(movement_encoder.parameters()) +\n",
    "    list(tabular_encoder.parameters()) +\n",
    "    list(classifier.parameters()), lr=1e-3)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for movement, tabular, labels in dataloader:\n",
    "        # Forward pass\n",
    "        movement_feat = movement_encoder(movement)  # shape [B, 64]\n",
    "        tabular_feat = tabular_encoder(tabular)\n",
    "        fused = torch.cat([movement_feat, tabular_feat], dim=1)\n",
    "        output = classifier(fused)\n",
    "\n",
    "        # Loss and optimization\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        model_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}, Loss: {model_loss:.4f}, Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe297d9c-0abd-4f13-bb05-6bf413b80aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Deep Learning) CUDA 11.8",
   "language": "python",
   "name": "env_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
